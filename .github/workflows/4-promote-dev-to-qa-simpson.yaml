name: "üöÄ Promote Dev ‚Üí QA - simpson"

on:
  workflow_dispatch:
    inputs:
      dev_image_tag:
        description: 'Dev image tag to promote (leave empty for latest)'
        required: false
        type: string
  workflow_call:
    inputs:
      dev_image_tag:
        description: 'Dev image tag to promote'
        required: false
        type: string

permissions:
  contents: write
  security-events: write

env:
  APP_NAME: simpson
  TENANT: opsera
  SOURCE_ENV: dev
  TARGET_ENV: qa
  AWS_REGION: us-west-2
  HUB_CLUSTER: argocd-usw2
  SPOKE_CLUSTER: opsera-usw2-np
  ARGOCD_SERVER: argocd-usw2.agent.opsera.dev
  APP_FOLDER: .opsera-simpson

concurrency:
  group: promote-simpson-dev-to-qa-${{ github.ref }}
  cancel-in-progress: false

jobs:
  # Stage 1: Get Latest Dev Image
  get-dev-image:
    name: "üì¶ Get Latest Dev Image"
    runs-on: ubuntu-latest
    outputs:
      dev_image_tag: ${{ steps.get-tag.outputs.dev_image_tag }}
      qa_image_tag: ${{ steps.get-tag.outputs.qa_image_tag }}
      ecr_uri: ${{ steps.get-tag.outputs.ecr_uri }}
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Get Image Tag
        id: get-tag
        run: |
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          ECR_REPO="${TENANT}/${APP_NAME}"
          ECR_URI="${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${ECR_REPO}"

          if [ -n "${{ inputs.dev_image_tag }}" ]; then
            DEV_TAG="${{ inputs.dev_image_tag }}"
            echo "Using provided dev image tag: $DEV_TAG"
          else
            # Get latest dev image from ECR (filter dev- tags FIRST, then sort)
            DEV_TAG=$(aws ecr describe-images \
              --repository-name "${ECR_REPO}" \
              --region ${AWS_REGION} \
              --output json | \
              jq -r '.imageDetails[] |
                select(.imageTags != null) |
                {tags: .imageTags, pushed: .imagePushedAt} |
                .tags[] |
                select(startswith("dev-"))' | \
              head -1)

            if [ -z "$DEV_TAG" ]; then
              echo "‚ùå No dev images found in ECR"
              echo "Listing all available images:"
              aws ecr describe-images \
                --repository-name "${ECR_REPO}" \
                --region ${AWS_REGION} \
                --query 'imageDetails[*].imageTags[0]' \
                --output text | head -10
              exit 1
            fi
            echo "Found latest dev image: $DEV_TAG"
          fi

          # Generate QA tag by replacing dev- prefix with qa-
          QA_TAG=$(echo "$DEV_TAG" | sed 's/^dev-/qa-/')

          echo "dev_image_tag=$DEV_TAG" >> $GITHUB_OUTPUT
          echo "qa_image_tag=$QA_TAG" >> $GITHUB_OUTPUT
          echo "ecr_uri=$ECR_URI" >> $GITHUB_OUTPUT

          echo "‚úÖ Dev image: ${ECR_URI}:${DEV_TAG}"
          echo "‚úÖ QA image: ${ECR_URI}:${QA_TAG}"

  # Stage 2: Re-tag Image for QA
  retag-image:
    name: "üè∑Ô∏è Re-tag Image for QA"
    runs-on: ubuntu-latest
    needs: get-dev-image
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Re-tag Image
        run: |
          ECR_URI="${{ needs.get-dev-image.outputs.ecr_uri }}"
          DEV_TAG="${{ needs.get-dev-image.outputs.dev_image_tag }}"
          QA_TAG="${{ needs.get-dev-image.outputs.qa_image_tag }}"

          # Check if QA tag already exists
          if aws ecr describe-images \
            --repository-name "${TENANT}/${APP_NAME}" \
            --image-ids imageTag=${QA_TAG} \
            --region ${AWS_REGION} &>/dev/null; then
            echo "‚úì QA tag already exists: ${QA_TAG}"
            echo "‚úÖ Image already tagged: ${ECR_URI}:${QA_TAG}"
            exit 0
          fi

          # Get image manifest
          MANIFEST=$(aws ecr batch-get-image \
            --repository-name "${TENANT}/${APP_NAME}" \
            --image-ids imageTag=${DEV_TAG} \
            --region ${AWS_REGION} \
            --query 'images[0].imageManifest' \
            --output text)

          # Put manifest with new QA tag
          aws ecr put-image \
            --repository-name "${TENANT}/${APP_NAME}" \
            --image-tag ${QA_TAG} \
            --image-manifest "$MANIFEST" \
            --region ${AWS_REGION} 2>&1 | grep -v "ImageAlreadyExistsException" || true

          echo "‚úÖ Image re-tagged: ${ECR_URI}:${QA_TAG}"

  # Stage 3: Create QA Namespace (if not exists)
  create-qa-namespace:
    name: "üìÅ Create QA Namespace"
    runs-on: ubuntu-latest
    needs: retag-image
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Kubeconfig
        run: |
          aws eks update-kubeconfig --name ${SPOKE_CLUSTER} --region ${AWS_REGION} --alias spoke

      - name: Create Namespace
        run: |
          NS="${TENANT}-${APP_NAME}-${TARGET_ENV}"

          if kubectl --context spoke get namespace $NS 2>/dev/null; then
            echo "‚úì Namespace already exists: $NS"
          else
            kubectl --context spoke create namespace $NS
            kubectl --context spoke label namespace $NS \
              app=${APP_NAME} \
              tenant=${TENANT} \
              environment=${TARGET_ENV}
            echo "‚úÖ Created namespace: $NS"
          fi

  # Stage 4: Update QA Manifests
  update-qa-manifests:
    name: "üìù Update QA Manifests"
    runs-on: ubuntu-latest
    needs: [get-dev-image, create-qa-namespace]
    steps:
      - uses: actions/checkout@v4
        with:
          token: ${{ secrets.GH_PAT }}

      - name: Configure Git
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

      - name: Update Kustomization
        run: |
          KUSTOMIZATION="${APP_FOLDER}/k8s/overlays/${TARGET_ENV}/kustomization.yaml"
          IMAGE_TAG="${{ needs.get-dev-image.outputs.qa_image_tag }}"
          ECR_URI="${{ needs.get-dev-image.outputs.ecr_uri }}"

          echo "Updating: $KUSTOMIZATION"

          # Pull FIRST before modifications
          git pull --rebase origin ${GITHUB_REF_NAME}
          echo "‚úì Pulled latest changes"

          # Update with sed
          sed -i.bak "s|newName:.*${APP_NAME}.*|newName: ${ECR_URI}|g" "$KUSTOMIZATION"
          sed -i.bak "s|newTag:.*|newTag: ${IMAGE_TAG}|g" "$KUSTOMIZATION"
          rm -f "${KUSTOMIZATION}.bak"

          echo "‚úÖ Updated manifest"
          cat "$KUSTOMIZATION"

      - name: Commit and Push with Retry
        run: |
          KUSTOMIZATION="${APP_FOLDER}/k8s/overlays/${TARGET_ENV}/kustomization.yaml"
          IMAGE_TAG="${{ needs.get-dev-image.outputs.qa_image_tag }}"

          # Stage changes
          git add "$KUSTOMIZATION"

          # Commit
          git commit -m "chore(promote): promote ${SOURCE_ENV} to ${TARGET_ENV} - ${IMAGE_TAG} [skip ci]"

          # Retry loop for push
          for i in 1 2 3; do
            echo "Push attempt $i/3..."
            if git push origin ${GITHUB_REF_NAME}; then
              echo "‚úÖ Manifest updated and pushed successfully"
              break
            fi

            echo "‚ö†Ô∏è Push failed, pulling latest and retrying..."
            git pull --rebase origin ${GITHUB_REF_NAME}
            sleep 2

            if [ $i -eq 3 ]; then
              echo "‚ùå Failed to push after 3 attempts"
              exit 1
            fi
          done

  # Stage 5: Validate Manifests (FAST FAIL)
  validate-manifests:
    name: "üîç Validate Manifests"
    runs-on: ubuntu-latest
    needs: update-qa-manifests
    steps:
      - uses: actions/checkout@v4
        with:
          ref: main

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: Build and Validate Kustomize
        run: |
          echo "Building kustomize manifests for ${TARGET_ENV}..."
          kubectl kustomize ${APP_FOLDER}/k8s/overlays/${TARGET_ENV} > /tmp/manifests.yaml

          echo "‚úÖ Kustomize build successful"

          # Check for placeholder values
          if grep -q "PLACEHOLDER" /tmp/manifests.yaml; then
            echo "‚ùå Found PLACEHOLDER values in manifests"
            grep "PLACEHOLDER" /tmp/manifests.yaml
            exit 1
          fi

          # Check for empty image tags
          if grep -q "newTag: latest" /tmp/manifests.yaml && [ "${TARGET_ENV}" != "dev" ]; then
            echo "‚ö†Ô∏è Warning: Using 'latest' tag in non-dev environment"
          fi

          echo "‚úÖ Manifest validation passed"
          echo "Generated manifest size: $(wc -l < /tmp/manifests.yaml) lines"

      - name: Upload Manifests
        uses: actions/upload-artifact@v4
        with:
          name: validated-manifests
          path: /tmp/manifests.yaml
          retention-days: 7

  # Stage 6: Create/Update ArgoCD Application
  create-argocd-app:
    name: "üìã Create/Update ArgoCD App"
    runs-on: ubuntu-latest
    needs: validate-manifests
    steps:
      - uses: actions/checkout@v4
        with:
          ref: main

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Kubeconfig
        run: |
          aws eks update-kubeconfig --name ${HUB_CLUSTER} --region ${AWS_REGION} --alias hub

      - name: Create or Update ArgoCD Application
        run: |
          kubectl --context hub apply -f ${APP_FOLDER}/argocd/${TARGET_ENV}/application.yaml
          kubectl --context hub get application ${APP_NAME}-${TARGET_ENV} -n argocd
          echo "‚úÖ ArgoCD application created/updated"

  # Stage 7: Refresh ECR Secret
  refresh-ecr-secret:
    name: "üîê Refresh ECR Secret"
    runs-on: ubuntu-latest
    needs: [create-argocd-app, get-dev-image]
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Kubeconfig
        run: |
          aws eks update-kubeconfig --name ${SPOKE_CLUSTER} --region ${AWS_REGION} --alias spoke

      - name: Refresh ECR Pull Secret
        run: |
          NS="${TENANT}-${APP_NAME}-${TARGET_ENV}"
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)

          ECR_PASS=$(aws ecr get-login-password --region ${AWS_REGION})

          kubectl --context spoke create secret docker-registry ecr-pull-secret \
            --docker-server="${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com" \
            --docker-username=AWS \
            --docker-password="$ECR_PASS" \
            --namespace="${NS}" \
            --dry-run=client -o yaml | kubectl --context spoke apply -f -

          echo "‚úÖ ECR secret refreshed (valid for 12 hours)"

  # Stage 8: Sync ArgoCD
  sync-argocd:
    name: "üîÑ Sync ArgoCD"
    runs-on: ubuntu-latest
    needs: [refresh-ecr-secret]
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Kubeconfig
        run: |
          aws eks update-kubeconfig --name ${HUB_CLUSTER} --region ${AWS_REGION} --alias hub

      - name: Hard Refresh ArgoCD
        run: |
          kubectl --context hub -n argocd patch app ${APP_NAME}-${TARGET_ENV} \
            --type merge -p '{"operation":{"initiatedBy":{"username":"github-actions"},"info":[{"name":"Reason","value":"Promotion from dev to qa"}]}}'
          kubectl --context hub -n argocd annotate app ${APP_NAME}-${TARGET_ENV} \
            argocd.argoproj.io/refresh=hard --overwrite
          echo "‚úÖ ArgoCD hard refresh triggered"

      - name: Wait for Refresh to Complete
        run: |
          echo "Waiting for ArgoCD to refresh cache and generate manifests..."
          for i in {1..30}; do
            # Check if manifest generation succeeded
            SYNC_STATUS=$(kubectl --context hub -n argocd get app ${APP_NAME}-${TARGET_ENV} -o jsonpath='{.status.sync.status}' 2>/dev/null || echo "Unknown")
            SOURCE_TYPE=$(kubectl --context hub -n argocd get app ${APP_NAME}-${TARGET_ENV} -o jsonpath='{.status.sourceType}' 2>/dev/null || echo "Unknown")

            # Check for manifest generation errors
            CONDITIONS=$(kubectl --context hub -n argocd get app ${APP_NAME}-${TARGET_ENV} -o jsonpath='{.status.conditions}' 2>/dev/null || echo "[]")

            echo "[$i/30] Status: $SYNC_STATUS, SourceType: $SOURCE_TYPE"

            # If we see ComparisonError, the cache is still stale
            if echo "$CONDITIONS" | grep -q "ComparisonError"; then
              echo "‚ö†Ô∏è Manifest generation error detected, continuing to wait..."
              sleep 10
              continue
            fi

            # If source type is detected and no errors, refresh is complete
            if [ "$SOURCE_TYPE" != "Unknown" ] && [ "$SOURCE_TYPE" != "" ]; then
              echo "‚úÖ Cache refresh complete, manifests regenerated"
              break
            fi

            sleep 10
          done

          # Final check for errors
          ERROR_MSG=$(kubectl --context hub -n argocd get app ${APP_NAME}-${TARGET_ENV} -o jsonpath='{.status.conditions[?(@.type=="ComparisonError")].message}' 2>/dev/null || echo "")
          if [ -n "$ERROR_MSG" ]; then
            echo "‚ùå Manifest generation still failing after refresh:"
            echo "$ERROR_MSG"
            exit 1
          fi

          echo "‚úÖ Ready to sync"

      - name: Sync and Wait
        run: |
          kubectl --context hub -n argocd patch app ${APP_NAME}-${TARGET_ENV} \
            --type merge -p '{"operation":{"sync":{"revision":"main"}}}'

          echo "Waiting for sync to complete..."
          for i in {1..60}; do
            STATUS=$(kubectl --context hub -n argocd get app ${APP_NAME}-${TARGET_ENV} -o jsonpath='{.status.sync.status}')
            HEALTH=$(kubectl --context hub -n argocd get app ${APP_NAME}-${TARGET_ENV} -o jsonpath='{.status.health.status}')

            echo "Attempt $i/60 - Sync: $STATUS, Health: $HEALTH"

            if [ "$STATUS" = "Synced" ] && { [ "$HEALTH" = "Healthy" ] || [ "$HEALTH" = "Progressing" ]; }; then
              echo "‚úÖ Application synced"
              exit 0
            fi

            sleep 10
          done

          echo "‚ö†Ô∏è Sync timeout - check ArgoCD manually"
          exit 1

  # Stage 9: Monitor Canary Rollout
  monitor-canary:
    name: "üìä Monitor Canary Rollout"
    runs-on: ubuntu-latest
    needs: sync-argocd
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Kubeconfig
        run: |
          aws eks update-kubeconfig --name ${SPOKE_CLUSTER} --region ${AWS_REGION} --alias spoke

      - name: Monitor Rollout
        run: |
          NS="${TENANT}-${APP_NAME}-${TARGET_ENV}"

          echo "Monitoring canary rollout..."
          for i in {1..60}; do
            STATUS=$(kubectl --context spoke -n ${NS} get rollout ${APP_NAME} -o jsonpath='{.status.phase}' 2>/dev/null || echo "NotFound")

            echo "[$i/60] Rollout status: $STATUS"

            if [ "$STATUS" = "Healthy" ]; then
              echo "‚úÖ Canary rollout completed successfully"
              kubectl --context spoke -n ${NS} get rollout ${APP_NAME}
              exit 0
            elif [ "$STATUS" = "Degraded" ]; then
              echo "‚ùå Rollout degraded - checking details..."
              kubectl --context spoke -n ${NS} describe rollout ${APP_NAME}
              exit 1
            fi

            sleep 10
          done

          echo "‚ö†Ô∏è Rollout monitoring timeout"
          kubectl --context spoke -n ${NS} get rollout ${APP_NAME}

  # Stage 10: Verify Deployment
  verify-deployment:
    name: "‚úÖ Verify Deployment"
    runs-on: ubuntu-latest
    needs: monitor-canary
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Kubeconfig
        run: |
          aws eks update-kubeconfig --name ${SPOKE_CLUSTER} --region ${AWS_REGION} --alias spoke

      - name: Verify Pods
        run: |
          NS="${TENANT}-${APP_NAME}-${TARGET_ENV}"
          kubectl --context spoke get pods -n ${NS} -l app=${APP_NAME}
          echo "‚úÖ Pods verified"

      - name: Verify Services
        run: |
          NS="${TENANT}-${APP_NAME}-${TARGET_ENV}"
          kubectl --context spoke get svc -n ${NS}
          echo "‚úÖ Services verified"

      - name: Verify Ingress
        run: |
          NS="${TENANT}-${APP_NAME}-${TARGET_ENV}"
          kubectl --context spoke get ingress -n ${NS} ${APP_NAME}
          echo "‚úÖ Ingress verified"

  # Stage 11: Promotion Summary
  promotion-summary:
    name: "üìä Promotion Summary"
    runs-on: ubuntu-latest
    needs: [get-dev-image, verify-deployment]
    steps:
      - name: Generate Summary
        run: |
          cat << 'EOF' >> $GITHUB_STEP_SUMMARY
          # üéâ Promotion Complete - Dev ‚Üí QA

          ## Promoted Image

          - **Source:** dev-${{ needs.get-dev-image.outputs.dev_image_tag }}
          - **Target:** qa-${{ needs.get-dev-image.outputs.qa_image_tag }}
          - **ECR URI:** ${{ needs.get-dev-image.outputs.ecr_uri }}

          ## Deployment Details

          - **Environment**: qa
          - **Strategy**: Canary (20% ‚Üí 40% ‚Üí 60% ‚Üí 80% ‚Üí 100%)
          - **Namespace**: opsera-simpson-qa
          - **Cluster**: opsera-usw2-np

          ## Access

          - **Application URL**: http://simpson-qa.agent.opsera.dev
          - **ArgoCD**: https://argocd-usw2.agent.opsera.dev/applications/simpson-qa

          ## Canary Rollout

          ‚úÖ Initial deployment (20% traffic)
          ‚úÖ Health analysis passed
          ‚úÖ Progressive rollout to 100%
          ‚úÖ Canary promotion complete

          EOF
