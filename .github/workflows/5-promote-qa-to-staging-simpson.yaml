name: "üöÄ Promote QA ‚Üí Staging - simpson"

on:
  workflow_dispatch:
    inputs:
      qa_image_tag:
        description: 'QA image tag to promote (leave empty for latest)'
        required: false
        type: string

permissions:
  contents: write

env:
  APP_NAME: simpson
  TENANT: opsera
  SOURCE_ENV: qa
  TARGET_ENV: staging
  AWS_REGION: us-west-2
  HUB_CLUSTER: argocd-usw2
  SPOKE_CLUSTER: opsera-usw2-np
  ARGOCD_SERVER: argocd-usw2.agent.opsera.dev
  APP_FOLDER: .opsera-simpson

concurrency:
  group: promote-simpson-qa-staging-${{ github.ref }}
  cancel-in-progress: false

jobs:
  # Stage 1: Get Latest QA Image
  get-qa-image:
    name: "üì¶ Get Latest QA Image"
    runs-on: ubuntu-latest
    outputs:
      qa_image_tag: ${{ steps.get-tag.outputs.qa_image_tag }}
      staging_image_tag: ${{ steps.get-tag.outputs.staging_image_tag }}
      ecr_uri: ${{ steps.get-tag.outputs.ecr_uri }}
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Get Image Tag
        id: get-tag
        run: |
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          ECR_REPO="${TENANT}/${APP_NAME}"
          ECR_URI="${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${ECR_REPO}"

          if [ -n "${{ inputs.qa_image_tag }}" ]; then
            QA_TAG="${{ inputs.qa_image_tag }}"
            echo "Using provided QA image tag: $QA_TAG"
          else
            # Get latest QA image from ECR (filter qa- tags FIRST, then sort)
            QA_TAG=$(aws ecr describe-images \
              --repository-name "${ECR_REPO}" \
              --region ${AWS_REGION} \
              --output json | \
              jq -r '.imageDetails[] |
                select(.imageTags != null) |
                {tags: .imageTags, pushed: .imagePushedAt} |
                .tags[] |
                select(startswith("qa-"))' | \
              head -1)

            if [ -z "$QA_TAG" ]; then
              echo "‚ùå No QA images found in ECR"
              echo "Listing all available images:"
              aws ecr describe-images \
                --repository-name "${ECR_REPO}" \
                --region ${AWS_REGION} \
                --query 'imageDetails[*].imageTags[0]' \
                --output text | head -10
              exit 1
            fi
            echo "Found latest QA image: $QA_TAG"
          fi

          # Generate Staging tag by replacing qa- prefix with staging-
          STAGING_TAG=$(echo "$QA_TAG" | sed 's/^qa-/staging-/')

          echo "qa_image_tag=$QA_TAG" >> $GITHUB_OUTPUT
          echo "staging_image_tag=$STAGING_TAG" >> $GITHUB_OUTPUT
          echo "ecr_uri=$ECR_URI" >> $GITHUB_OUTPUT

          echo "‚úÖ QA image: ${ECR_URI}:${QA_TAG}"
          echo "‚úÖ Staging image: ${ECR_URI}:${STAGING_TAG}"

  # Stage 2: Re-tag Image for Staging
  retag-image:
    name: "üè∑Ô∏è Re-tag Image for Staging"
    runs-on: ubuntu-latest
    needs: get-qa-image
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Re-tag Image
        run: |
          QA_TAG="${{ needs.get-qa-image.outputs.qa_image_tag }}"
          STAGING_TAG="${{ needs.get-qa-image.outputs.staging_image_tag }}"
          ECR_URI="${{ needs.get-qa-image.outputs.ecr_uri }}"

          # Check if staging tag already exists (idempotent)
          if aws ecr describe-images \
            --repository-name "${TENANT}/${APP_NAME}" \
            --image-ids imageTag=${STAGING_TAG} \
            --region ${AWS_REGION} &>/dev/null; then
            echo "‚úì Staging tag already exists: ${STAGING_TAG}"
            exit 0
          fi

          # Get manifest from QA image
          MANIFEST=$(aws ecr batch-get-image \
            --repository-name "${TENANT}/${APP_NAME}" \
            --image-ids imageTag=${QA_TAG} \
            --output json | \
            jq -r '.images[0].imageManifest')

          # Re-tag with staging tag
          aws ecr put-image \
            --repository-name "${TENANT}/${APP_NAME}" \
            --image-tag ${STAGING_TAG} \
            --image-manifest "$MANIFEST" \
            --region ${AWS_REGION}

          echo "‚úÖ Re-tagged ${QA_TAG} ‚Üí ${STAGING_TAG}"

  # Stage 3: Create Staging Namespace
  create-staging-namespace:
    name: "üìÅ Create Staging Namespace"
    runs-on: ubuntu-latest
    needs: retag-image
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Kubeconfig
        run: |
          aws eks update-kubeconfig \
            --name ${SPOKE_CLUSTER} \
            --region ${AWS_REGION} \
            --alias spoke

      - name: Create Namespace
        run: |
          NS="${TENANT}-${APP_NAME}-${TARGET_ENV}"

          if kubectl --context spoke get namespace ${NS} &>/dev/null; then
            echo "‚úì Namespace already exists: ${NS}"
          else
            kubectl --context spoke create namespace ${NS}
            echo "‚úÖ Namespace created: ${NS}"
          fi

  # Stage 4: Update Staging Manifests
  update-staging-manifests:
    name: "üìù Update Staging Manifests"
    runs-on: ubuntu-latest
    needs: [get-qa-image, create-staging-namespace]
    steps:
      - uses: actions/checkout@v4
        with:
          token: ${{ secrets.GH_PAT }}

      - name: Configure Git
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

      - name: Update Kustomization
        run: |
          KUSTOMIZATION="${APP_FOLDER}/k8s/overlays/${TARGET_ENV}/kustomization.yaml"
          IMAGE_TAG="${{ needs.get-qa-image.outputs.staging_image_tag }}"
          ECR_URI="${{ needs.get-qa-image.outputs.ecr_uri }}"

          echo "Updating: $KUSTOMIZATION"

          # Pull FIRST before modifications
          git pull --rebase origin ${GITHUB_REF_NAME}
          echo "‚úì Pulled latest changes"

          # Update with sed
          sed -i.bak "s|newName:.*${APP_NAME}.*|newName: ${ECR_URI}|g" "$KUSTOMIZATION"
          sed -i.bak "s|newTag:.*|newTag: ${IMAGE_TAG}|g" "$KUSTOMIZATION"
          rm -f "${KUSTOMIZATION}.bak"

          echo "‚úÖ Updated manifest"
          cat "$KUSTOMIZATION"

      - name: Commit and Push with Retry
        run: |
          KUSTOMIZATION="${APP_FOLDER}/k8s/overlays/${TARGET_ENV}/kustomization.yaml"
          IMAGE_TAG="${{ needs.get-qa-image.outputs.staging_image_tag }}"

          # Stage changes
          git add "$KUSTOMIZATION"

          # Check if there are changes to commit (idempotent)
          if git diff --cached --quiet; then
            echo "‚úì Manifest already up-to-date (${IMAGE_TAG})"
            echo "‚úÖ No changes needed - desired state already achieved"
            exit 0
          fi

          # Commit
          git commit -m "chore(promote): promote ${SOURCE_ENV} to ${TARGET_ENV} - ${IMAGE_TAG} [skip ci]"

          # Retry loop for push
          for i in 1 2 3; do
            echo "Push attempt $i/3..."
            if git push origin ${GITHUB_REF_NAME}; then
              echo "‚úÖ Manifest updated and pushed successfully"
              break
            fi

            echo "‚ö†Ô∏è Push failed, pulling latest and retrying..."
            git pull --rebase origin ${GITHUB_REF_NAME}
            sleep 2

            if [ $i -eq 3 ]; then
              echo "‚ùå Failed to push after 3 attempts"
              exit 1
            fi
          done

  # Stage 5: Validate Manifests (FAST FAIL)
  validate-manifests:
    name: "üîç Validate Manifests"
    runs-on: ubuntu-latest
    needs: update-staging-manifests
    steps:
      - uses: actions/checkout@v4
        with:
          ref: main

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: Build and Validate Kustomize
        run: |
          echo "Building kustomize manifests for ${TARGET_ENV}..."
          kubectl kustomize ${APP_FOLDER}/k8s/overlays/${TARGET_ENV} > /tmp/manifests.yaml

          echo "‚úÖ Kustomize build successful"

          # Check for placeholder values
          if grep -q "PLACEHOLDER" /tmp/manifests.yaml; then
            echo "‚ùå Found PLACEHOLDER values in manifests"
            grep "PLACEHOLDER" /tmp/manifests.yaml
            exit 1
          fi

          # Check for empty image tags
          if grep -q "newTag: latest" /tmp/manifests.yaml && [ "${TARGET_ENV}" != "dev" ]; then
            echo "‚ö†Ô∏è Warning: Using 'latest' tag in non-dev environment"
          fi

          echo "‚úÖ Manifest validation passed"
          echo "Generated manifest size: $(wc -l < /tmp/manifests.yaml) lines"

      - name: Upload Manifests
        uses: actions/upload-artifact@v4
        with:
          name: validated-manifests
          path: /tmp/manifests.yaml
          retention-days: 7

  # Stage 6: Create/Update ArgoCD App
  create-argocd-app:
    name: "üìã Create/Update ArgoCD App"
    runs-on: ubuntu-latest
    needs: validate-manifests
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: Setup Kubeconfig
        run: |
          aws eks update-kubeconfig \
            --name ${HUB_CLUSTER} \
            --region ${AWS_REGION} \
            --alias hub

          aws eks update-kubeconfig \
            --name ${SPOKE_CLUSTER} \
            --region ${AWS_REGION} \
            --alias spoke

      - name: Create or Update ArgoCD Application
        run: |
          APP="${APP_NAME}-${TARGET_ENV}"
          NS="${TENANT}-${APP_NAME}-${TARGET_ENV}"
          REPO_URL="https://github.com/${GITHUB_REPOSITORY}.git"
          MANIFEST_PATH="${APP_FOLDER}/k8s/overlays/${TARGET_ENV}"

          # Create ArgoCD Application manifest
          cat > /tmp/argocd-app.yaml <<'EOF'
          apiVersion: argoproj.io/v1alpha1
          kind: Application
          metadata:
            name: APP_NAME_PLACEHOLDER
            namespace: argocd
          spec:
            project: default
            source:
              repoURL: REPO_URL_PLACEHOLDER
              targetRevision: HEAD
              path: PATH_PLACEHOLDER
            destination:
              server: https://kubernetes.default.svc
              namespace: NAMESPACE_PLACEHOLDER
            syncPolicy:
              automated:
                prune: true
                selfHeal: true
              syncOptions:
                - CreateNamespace=true
          EOF

          # Replace placeholders
          sed -i "s|APP_NAME_PLACEHOLDER|${APP}|g" /tmp/argocd-app.yaml
          sed -i "s|REPO_URL_PLACEHOLDER|${REPO_URL}|g" /tmp/argocd-app.yaml
          sed -i "s|PATH_PLACEHOLDER|${MANIFEST_PATH}|g" /tmp/argocd-app.yaml
          sed -i "s|NAMESPACE_PLACEHOLDER|${NS}|g" /tmp/argocd-app.yaml

          # Apply manifest
          kubectl --context hub apply -f /tmp/argocd-app.yaml

          echo "‚úÖ ArgoCD application created/updated: ${APP}"

  # Stage 7: Refresh ECR Secret
  refresh-ecr-secret:
    name: "üîê Refresh ECR Secret"
    runs-on: ubuntu-latest
    needs: create-argocd-app
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: Setup Kubeconfig
        run: |
          aws eks update-kubeconfig \
            --name ${SPOKE_CLUSTER} \
            --region ${AWS_REGION} \
            --alias spoke

      - name: Refresh ECR Pull Secret
        run: |
          NS="${TENANT}-${APP_NAME}-${TARGET_ENV}"
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          ECR_REGISTRY="${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com"

          # Get ECR token
          TOKEN=$(aws ecr get-login-password --region ${AWS_REGION})

          # Delete old secret if exists
          kubectl --context spoke delete secret ecr-pull-secret -n ${NS} --ignore-not-found

          # Create new secret
          kubectl --context spoke create secret docker-registry ecr-pull-secret \
            --docker-server=${ECR_REGISTRY} \
            --docker-username=AWS \
            --docker-password=${TOKEN} \
            -n ${NS}

          echo "‚úÖ ECR pull secret refreshed"

  # Stage 8: Sync ArgoCD
  sync-argocd:
    name: "üîÑ Sync ArgoCD"
    runs-on: ubuntu-latest
    needs: refresh-ecr-secret
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: Setup Kubeconfig
        run: |
          aws eks update-kubeconfig \
            --name ${HUB_CLUSTER} \
            --region ${AWS_REGION} \
            --alias hub

      - name: Hard Refresh ArgoCD
        run: |
          APP="${APP_NAME}-${TARGET_ENV}"
          kubectl --context hub -n argocd patch app ${APP} \
            --type json \
            -p='[{"op": "replace", "path": "/spec/source/targetRevision", "value": "HEAD"}]'

          kubectl --context hub -n argocd annotate app ${APP} \
            argocd.argoproj.io/refresh=hard --overwrite

          echo "‚úÖ Hard refresh triggered"

      - name: Wait for Refresh to Complete
        run: |
          APP="${APP_NAME}-${TARGET_ENV}"
          for i in {1..30}; do
            CONDITIONS=$(kubectl --context hub -n argocd get app ${APP} -o jsonpath='{.status.conditions}')
            if echo "$CONDITIONS" | grep -q "ComparisonError"; then
              echo "Waiting for cache refresh... ($i/30)"
              sleep 10
              continue
            fi
            echo "‚úì Cache refreshed"
            break
          done

      - name: Sync and Wait
        run: |
          APP="${APP_NAME}-${TARGET_ENV}"
          kubectl --context hub -n argocd patch app ${APP} \
            --type merge \
            -p '{"operation":{"initiatedBy":{"username":"github-actions"},"sync":{"revision":"HEAD"}}}'

          echo "‚è≥ Waiting for sync to complete..."
          kubectl --context hub -n argocd wait app/${APP} \
            --for=jsonpath='{.status.sync.status}'=Synced \
            --timeout=5m || true

          echo "‚úÖ ArgoCD sync completed"

  # Stage 9: Monitor Blue-Green Rollout
  monitor-bluegreen:
    name: "üìä Monitor Blue-Green Rollout"
    runs-on: ubuntu-latest
    needs: sync-argocd
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: Setup Kubeconfig
        run: |
          aws eks update-kubeconfig \
            --name ${SPOKE_CLUSTER} \
            --region ${AWS_REGION} \
            --alias spoke

      - name: Monitor Rollout
        run: |
          NS="${TENANT}-${APP_NAME}-${TARGET_ENV}"

          echo "Monitoring blue-green rollout..."
          for i in {1..60}; do
            STATUS=$(kubectl --context spoke -n ${NS} get rollout ${APP_NAME} -o jsonpath='{.status.phase}' 2>/dev/null || echo "NotFound")

            echo "[$i/60] Rollout status: $STATUS"

            if [ "$STATUS" = "Healthy" ]; then
              echo "‚úÖ Blue-Green rollout completed successfully"
              kubectl --context spoke -n ${NS} get rollout ${APP_NAME}
              echo ""
              echo "üìò Blue-Green Deployment Info:"
              echo "  Active Service: simpson-active (live traffic)"
              echo "  Preview Service: simpson-preview (new version for testing)"
              echo "  Auto-promotion: 5 minutes (or manual via kubectl argo rollouts promote)"
              exit 0
            elif [ "$STATUS" = "Degraded" ]; then
              echo "‚ùå Rollout degraded - checking details..."
              kubectl --context spoke -n ${NS} describe rollout ${APP_NAME}
              exit 1
            fi

            sleep 10
          done

          echo "‚ö†Ô∏è Rollout monitoring timeout"
          kubectl --context spoke -n ${NS} get rollout ${APP_NAME}

  # Stage 10: Verify Deployment
  verify-deployment:
    name: "‚úÖ Verify Deployment"
    runs-on: ubuntu-latest
    needs: monitor-bluegreen
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: Setup Kubeconfig
        run: |
          aws eks update-kubeconfig \
            --name ${SPOKE_CLUSTER} \
            --region ${AWS_REGION} \
            --alias spoke

      - name: Verify Pods
        run: |
          NS="${TENANT}-${APP_NAME}-${TARGET_ENV}"

          echo "Checking pod status..."
          kubectl --context spoke -n ${NS} get pods -l app=${APP_NAME}

          READY=$(kubectl --context spoke -n ${NS} get pods -l app=${APP_NAME} -o jsonpath='{.items[*].status.conditions[?(@.type=="Ready")].status}' | grep -o "True" | wc -l)

          if [ "$READY" -gt 0 ]; then
            echo "‚úÖ $READY pod(s) ready"
          else
            echo "‚ùå No pods ready"
            exit 1
          fi

  # Stage 11: Promotion Summary
  promotion-summary:
    name: "üìä Promotion Summary"
    runs-on: ubuntu-latest
    needs: [get-qa-image, verify-deployment]
    if: always()
    steps:
      - name: Summary
        run: |
          echo "üéâ QA ‚Üí Staging Promotion Complete!"
          echo ""
          echo "üì¶ Image: ${{ needs.get-qa-image.outputs.staging_image_tag }}"
          echo "üåç Environment: staging"
          echo "üîµ Strategy: Blue-Green"
          echo "üåê URL: http://simpson-staging.agent.opsera.dev/"
          echo ""
          echo "üìò Blue-Green Controls:"
          echo "  - Active (live): http://simpson-staging.agent.opsera.dev/"
          echo "  - Preview (test): Access via simpson-preview service"
          echo "  - Promote manually: kubectl argo rollouts promote simpson -n opsera-simpson-staging"
          echo "  - Auto-promotion: 5 minutes after deployment"
